{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and Analyze Project Report\n",
    "\n",
    "In this project, the aim is to collect data from various sources, assess and clean efficiently to use it in our analyses. \n",
    "\n",
    "## 1. Gathering data \n",
    "\n",
    "In this part, data was gathered using three different sources. \n",
    "\n",
    "First data, a tweet archive from WeRateDogs Twitter account was gathered manually by using the file provided. (twitter_archive_enhanced.csv) Second data, the tweet image predictions, was downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv. Third data, in which you can find retweet and favourite counts of each tweet, was gathered using Twitter API and Tweepy library. This file was stored in JSON format\n",
    "\n",
    "## 2. Assessing data\n",
    "\n",
    "Both visual assessment and programmatic assesment were performed. In visual assessment, data was scrolled from start to end. In programmatic assessment, various functions were used such as .info(), .describe() and value_counts(). After the assesment, the issues were listed below. \n",
    "\n",
    "#### Quality issues\n",
    "\n",
    "##### `twitter_archive` table\n",
    "1. Timestamp should be datetime object and Tweet id should be string\n",
    "2. Replies are included.\n",
    "3. Retweets are included.\n",
    "4. Full content of text is not visible\n",
    "5. Numerator values with decimals in text are not correct in column 'rating_numerator'.\n",
    "6. Ranking_numerator and ranking_denominator should be float.\n",
    "\n",
    "##### `image_data` table\n",
    "7. Tweet id should be string\n",
    "8. Lower case/upper case differences for dog breed names\n",
    "\n",
    "##### `count_data` table\n",
    "9. Tweet id should be string\n",
    "10. column name 'id' should be replaced by 'tweet_id'\n",
    "\n",
    "\n",
    "#### Tidiness issues\n",
    "##### `twitter_archive` table\n",
    "1. There are multiple columns indications the type of a dog (doggo, floofer, pupper, puppo) \n",
    "##### `image_data` table\n",
    "2. Breed_type column should be added to see the dominant breed prediction\n",
    "\n",
    "3. All databases should be merged by using commn tweet ids'\n",
    "\n",
    "## 3. Cleaning data\n",
    "\n",
    "In this part, the issues listed in assesment part were addressed. First of all, a new copy of these three datasets should be created to avoid mistakes in original data. Hence, three copies were created with a name ending of '..._clean'. A common procedure in cleaning was used in this project: Define, code and test.\n",
    "\n",
    "At the first step, the data types of various columns were corrected such as timestamp, tweet_id, ranking_numerator and ranking_denominator.\n",
    "Then, retweets and replies in twitter_archive were removed using in_reply_to_status_id and retweeted_status_id colums. After removal, the related redundant columns were removed such as in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp.\n",
    "\n",
    "In order to see the all text data in table, the column width was set to infinity. In order to fix the numerators indicated in decimals in text part were corrected in ranking_numerator column. For this part, tweet texts with decimals were found and corrected.\n",
    "\n",
    "Due to different lower and upper case letters in dog breed types, all dog breed types were converted to lower case for standardization. For the last part of fixing quality issues, the 'id' column name in count_data was changed to 'tweet_id'. \n",
    "\n",
    "In order to address tidiness issues, first, a new column 'dog_types' were created to merge doggo, floofer, pupper, puppo columns and other four columns were removed. For image_data, a new colum called 'dominant_breed' was introduced to show the most dominant breed prediction. At the end, all of the information from three datasets were merged using tweet_ids'and saved as 'twitter_archive_master.csv'file.\n",
    "\n",
    "## 4. Storing data\n",
    "\n",
    "The last version of the merged data explained in Section 3 was saved and stored as a csv file called 'twitter_archive_master.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
